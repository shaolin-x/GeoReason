{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06b45b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.ops import nearest_points\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9d5ecd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              name                geometry          states\n",
      "0             Acadia National Park    POINT (-68.21 44.35)           Maine\n",
      "1  National Park of American Samoa  POINT (-170.68 -14.25)  American Samoa\n",
      "2             Arches National Park   POINT (-109.57 38.68)            Utah\n",
      "3           Badlands National Park    POINT (-102.5 43.75)    South Dakota\n",
      "4           Big Bend National Park   POINT (-103.25 29.25)           Texas\n"
     ]
    }
   ],
   "source": [
    "# Load park coordinates\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "def load_parks(csv_path: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Load park coordinates from CSV and return a GeoDataFrame with WGS84 CRS.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
    "    df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')\n",
    "    df = df.dropna(subset=['latitude', 'longitude'])\n",
    "    parks_df = gpd.GeoDataFrame(\n",
    "        df,\n",
    "        geometry=gpd.points_from_xy(df['longitude'], df['latitude']),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    return parks_df\n",
    "\n",
    "parks_df=load_parks('../dataset/parks_coordinates.csv')\n",
    "print(parks_df[['name', 'geometry','states']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e3d31c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name                                           geometry\n",
      "0     Minnesota  POLYGON ((-89.95766 47.28691, -90.13175 47.292...\n",
      "1       Montana  POLYGON ((-116.04823 49.00037, -113.0595 49.00...\n",
      "2  North Dakota  POLYGON ((-97.22894 49.00089, -97.21414 48.902...\n",
      "3        Hawaii  MULTIPOLYGON (((-155.93665 19.05939, -155.9080...\n",
      "4         Idaho  POLYGON ((-116.04823 49.00037, -115.9678 47.95...\n"
     ]
    }
   ],
   "source": [
    "def load_states(states_path: str) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Load US states from shapefile, filter exclusions, return GeoDataFrame.\n",
    "    \"\"\"\n",
    "    EXCLUDED_STATES = {\n",
    "        \"American Samoa\", \"Guam\", \"Commonwealth of the Northern Mariana Islands\",\n",
    "        \"Puerto Rico\", \"United States Virgin Islands\"}\n",
    "    states = gpd.read_file(states_path)\n",
    "    states = states[~states['name'].isin(EXCLUDED_STATES)]\n",
    "    return states\n",
    "states_df=load_states('../dataset/ne_110m_admin_1_states_provinces/ne_110m_admin_1_states_provinces.shp')\n",
    "print(states_df[['name', 'geometry']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad176979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name                                           geometry\n",
      "0     Minnesota  POLYGON ((-89.95766 47.28691, -90.13175 47.292...\n",
      "1       Montana  POLYGON ((-116.04823 49.00037, -113.0595 49.00...\n",
      "2  North Dakota  POLYGON ((-97.22894 49.00089, -97.21414 48.902...\n",
      "3        Hawaii  MULTIPOLYGON (((-155.93665 19.05939, -155.9080...\n",
      "4         Idaho  POLYGON ((-116.04823 49.00037, -115.9678 47.95...\n"
     ]
    }
   ],
   "source": [
    "def load_timezones(timezones_path: str) :\n",
    "    \"\"\"\n",
    "    Load time zones from shapefile, filter exclusions, return GeoDataFrame.\n",
    "    \"\"\"\n",
    "    EXCLUDED_ZONES = {\"Chamorro\", \"Samoa\", \"Atlantic\"}\n",
    "    tz = gpd.read_file(timezones_path)\n",
    "    tz = tz[~tz['zone'].isin(EXCLUDED_ZONES)]\n",
    "    return tz\n",
    "\n",
    "tz_df=load_timezones('../dataset/NTAD_Time_Zones_467650596632424595/Time_Zones.shp')\n",
    "print(states_df[['name', 'geometry']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efde4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: staet row and timezone row, dirction('state' or 'zone', meaning finding relation from state to timezone or vice versa)\n",
    "# output: list of relations between state and timezone\n",
    "\n",
    "def calc_topology(state, timezone, direction):\n",
    "    upper = 0.98\n",
    "    lower = 0.02\n",
    "    geom_state = state.geometry\n",
    "    geom_other = timezone.geometry\n",
    "    inter = geom_state.intersection(geom_other)\n",
    "    ia = inter.area\n",
    "    area_state = geom_state.area\n",
    "    upper_area = upper * area_state\n",
    "    lower_area = lower * area_state\n",
    "\n",
    "    rels = []\n",
    "    if ia == 0:\n",
    "        if state['name'] == \"Utah\" and timezone.zone == \"Pacific\" :\n",
    "            rels.append(\"touch\")\n",
    "        elif state['name'] == \"Montana\" and timezone.zone == \"Central\":\n",
    "            rels.append(\"touch\")\n",
    "        else: rels.append(\"disjoint\")\n",
    "    if 0 < ia <= lower_area:\n",
    "        rels.append(\"touch\")\n",
    "    if lower_area <ia <= upper_area:\n",
    "        rels.append(\"overlaps\") \n",
    "    if ia >= upper_area:\n",
    "        special = {\"Iowa\", \"Missouri\", \"Arkansas\", \"West Virginia\"}\n",
    "        if state['name'] in special:\n",
    "            if(direction == \"state\"):\n",
    "                rels.append(\"within\")\n",
    "            else:   \n",
    "                rels.append(\"contains\")\n",
    "        elif state['name'] == \"Alaska\":\n",
    "            if(direction == \"zone\"):\n",
    "                rels.append(\"covered by\")\n",
    "            else:   \n",
    "                rels.append(\"covers\")\n",
    "        else:\n",
    "            if(direction == \"state\"):\n",
    "                rels.append(\"covered by\")\n",
    "            else:   \n",
    "                rels.append(\"covers\")\n",
    "    \n",
    "    return sorted(set(rels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c65984bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       state time_zone                                              query  \\\n",
      "0  Minnesota   Eastern  How is Minnesota state spatially related to Ea...   \n",
      "1  Minnesota   Central  How is Minnesota state spatially related to Ce...   \n",
      "2  Minnesota  Mountain  How is Minnesota state spatially related to Mo...   \n",
      "3  Minnesota   Pacific  How is Minnesota state spatially related to Pa...   \n",
      "4  Minnesota    Alaska  How is Minnesota state spatially related to Al...   \n",
      "\n",
      "       answer  \n",
      "0       touch  \n",
      "1  covered by  \n",
      "2    disjoint  \n",
      "3    disjoint  \n",
      "4    disjoint  \n"
     ]
    }
   ],
   "source": [
    "def generate_topo_queries(df_states, df_tz):\n",
    "    results = []\n",
    "\n",
    "    # 1) state → tz\n",
    "    for _, st in df_states.iterrows():\n",
    "        for _, tz in df_tz.iterrows():\n",
    "            rels = calc_topology(st, tz, \"state\")\n",
    "            results.append({\n",
    "                'state':     st['name'],\n",
    "                'time_zone': tz['zone'],\n",
    "                'query':     f\"How is {st['name']} state spatially related to {tz['zone']} Time Zone area?\",\n",
    "                'answer':    \", \".join(rels) if rels else \"none\"\n",
    "            })\n",
    "\n",
    "    # 2) tz → state\n",
    "    for _, tz in df_tz.iterrows():\n",
    "        for _, st in df_states.iterrows():\n",
    "            rels = calc_topology(st, tz, \"zone\")\n",
    "            results.append({\n",
    "                'state':     st['name'],\n",
    "                'time_zone': tz['zone'],\n",
    "                'query':     f\"How is {tz['zone']} Time Zone Area spatially related to {st['name']} state?\",\n",
    "                'answer':    \", \".join(rels) if rels else \"none\"\n",
    "            })\n",
    "\n",
    "    for tz1, tz2 in combinations(df_tz.itertuples(), 2):\n",
    "        for _, st in df_states.iterrows():\n",
    "            # Compute relations against each individual TZ\n",
    "            rels_tz1 = calc_topology(st, tz1, \"state\")\n",
    "            rels_tz2 = calc_topology(st, tz2, \"state\")\n",
    "\n",
    "            # If either relation list includes \"within, covered by\", consider it within the combined area\n",
    "            if \"within\" in rels_tz1 or \"within\" in rels_tz2:\n",
    "                results.append({\n",
    "                    'state':     st['name'],\n",
    "                    'time_zone': f\"{tz1.zone} and {tz2.zone}\",\n",
    "                    'query':     (\n",
    "                        f\"How is {st['name']} state spatially related to the combined area of \"\n",
    "                        f\"{tz1.zone} and {tz2.zone} Time Zones?\"\n",
    "                    ),\n",
    "                    'answer':    \"within\"\n",
    "                })\n",
    "                results.append({\n",
    "                    'state':     st['name'],\n",
    "                    'time_zone': f\"{tz1.zone} and {tz2.zone}\",\n",
    "                    'query':     (\n",
    "                        f\"How is the combined area of {tz1.zone} and {tz2.zone} Time Zones\"\n",
    "                        f\"spatially related to {st['name']} state?\"\n",
    "                    ),\n",
    "                    'answer':    \"contains\"\n",
    "                })\n",
    "                results.append({\n",
    "                    'state':     st['name'],\n",
    "                    'time_zone': f\"{tz1.zone} and {tz2.zone}\",\n",
    "                    'query':     (\n",
    "                        f\"How is {st['name']} state spatially related to its state area that falls into \"\n",
    "                        f\"the combined area of {tz1.zone} and {tz2.zone} Time Zones?\"\n",
    "                    ),\n",
    "                    'answer':    \"equals\"\n",
    "                })\n",
    "\n",
    "    topo_df = pd.DataFrame(results)\n",
    "    print(topo_df.head())\n",
    "\n",
    "    topo_df[['query', 'answer']].to_json(\n",
    "        '../GeoReason_T1_queries/topo_queries.json',\n",
    "        orient='records',\n",
    "        lines=True,\n",
    "        indent=2\n",
    "                )\n",
    "    return results\n",
    "\n",
    "pairs = generate_topo_queries(\n",
    "    df_states=states_df,\n",
    "    df_tz=tz_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "752a79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_direction(parks_gdf, row) -> list:\n",
    "    \"\"\"\n",
    "    Given row with 'park1' and 'park2', compute compass direction neighbors.\n",
    "    \"\"\"\n",
    "    # Lookup coordinates\n",
    "    p1 = parks_gdf.loc[parks_gdf['name'] == row['park1']].iloc[0]\n",
    "    p2 = parks_gdf.loc[parks_gdf['name'] == row['park2']].iloc[0]\n",
    "    lat1, lon1 = p1.latitude, p1.longitude\n",
    "    lat2, lon2 = p2.latitude, p2.longitude\n",
    "\n",
    "    # Calculate bearing\n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2)\n",
    "    d_lambda = math.radians(lon2 - lon1)\n",
    "    x = math.sin(d_lambda) * math.cos(phi2)\n",
    "    y = math.cos(phi1) * math.sin(phi2) - \\\n",
    "        math.sin(phi1) * math.cos(phi2) * math.cos(d_lambda)\n",
    "    bearing = (math.degrees(math.atan2(x, y)) + 360) % 360\n",
    "\n",
    "    # Map to compass directions including neighbors\n",
    "    directions = ['North', 'Northeast', 'East', 'Southeast',\n",
    "                  'South', 'Southwest', 'West', 'Northwest']\n",
    "    idx = int(((bearing + 22.5) % 360) / 45)\n",
    "    return directions[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb144dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_direction_queries(parks_df):\n",
    "    rows = []\n",
    "    for i in range(len(parks_df)):\n",
    "        park1 = parks_df.iloc[i]\n",
    "        \n",
    "        # Get indices of all other parks\n",
    "        other_indices = list(range(len(parks_df)))\n",
    "        other_indices.remove(i)\n",
    "        \n",
    "        # Randomly select 5 other parks   \n",
    "        for j in other_indices:\n",
    "            park2 = parks_df.iloc[j]\n",
    "            query = (\n",
    "            f\"What's the closest 8-point compass direction from {park1['name']} to {park2['name']}?\"\n",
    "            )\n",
    "            rows.append({\n",
    "                'park1': park1['name'],\n",
    "                'park2': park2['name'],\n",
    "                'query': query\n",
    "            })\n",
    "    dir_df = pd.DataFrame(rows)\n",
    "    dir_df['answer'] = dir_df.apply(lambda row: calc_direction(parks_df, row), axis=1)\n",
    "    dir_df[['query', 'answer']].to_json(\n",
    "        '../GeoReason_T1_queries/dir_queries.json',\n",
    "        orient='records',\n",
    "        lines=True,\n",
    "        indent=2,\n",
    "        force_ascii=False\n",
    "    )\n",
    "\n",
    "generate_direction_queries(parks_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "444dc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance given lats and longs of two parks\n",
    "def calc_park_to_park_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0  # Radius of Earth in kilometers\n",
    "\n",
    "    # Convert degrees to radians\n",
    "    lat1_rad = math.radians(lat1)\n",
    "    lon1_rad = math.radians(lon1)\n",
    "    lat2_rad = math.radians(lat2)\n",
    "    lon2_rad = math.radians(lon2)\n",
    "\n",
    "    # Differences\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "\n",
    "    # Haversine formula\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1a8b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distance_queries(parks_df):\n",
    "    nearest_parks = []\n",
    "    farthest_parks = []\n",
    "    for i in range(len(parks_df)):\n",
    "        park1 = parks_df.iloc[i]\n",
    "        \n",
    "        # Get indices of all other parks\n",
    "        other_indices = list(range(len(parks_df)))\n",
    "        other_indices.remove(i)\n",
    "        \n",
    "        # Calculate distances to all other parks\n",
    "        distances = []\n",
    "        for j in other_indices:\n",
    "            park2 = parks_df.iloc[j]\n",
    "            distance = calc_park_to_park_distance(park1['latitude'], park1['longitude'], park2['latitude'], park2['longitude'])\n",
    "            distances.append((park2['name'], distance))\n",
    "        \n",
    "        # Sort by distance\n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # Nearest and farthest parks\n",
    "        nearest_parks.append(distances[0])\n",
    "        farthest_parks.append(distances[-1])\n",
    "    # Create DataFrame for nearest and farthest parks\n",
    "    nearest_df = pd.DataFrame(nearest_parks, columns=['answer', 'nearest_distance'])\n",
    "    farthest_df = pd.DataFrame(farthest_parks, columns=['answer', 'farthest_distance'])\n",
    "    # Combine with original DataFrame\n",
    "    # new_gdf = pd.concat([gdf, nearest_df, farthest_df], axis=1)\n",
    "    nearest_df = pd.concat([parks_df['name'], nearest_df], axis=1)\n",
    "    farthest_df = pd.concat([parks_df['name'], farthest_df], axis=1)\n",
    "\n",
    "    # add query to nearest_df and farthest_df\n",
    "    nearest_df['query'] = nearest_df.apply(lambda row: f\"Which officially designated national park is the closest to {row['name']} in straight line distance?\", axis=1)\n",
    "    farthest_df['query'] = farthest_df.apply(lambda row: f\"Which officially designated national park is the farthest from {row['name']} in straight line distance?\", axis=1)\n",
    "\n",
    "\n",
    "    # Export queries + answers as JSON\n",
    "    nearest_df[['query', 'answer']].to_json(\n",
    "        '../GeoReason_T1_queries/dis_nearest_queries.json',\n",
    "        orient='records',\n",
    "        lines=True, indent=2, force_ascii=False\n",
    "    )\n",
    "\n",
    "    farthest_df[['query', 'answer']].to_json(\n",
    "        '../GeoReason_T1_queries/dis_farthest_queries.json',\n",
    "        orient='records',\n",
    "        lines=True, indent=2, force_ascii=False\n",
    "    )\n",
    "generate_distance_queries(parks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6770ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.ops as ops\n",
    "\n",
    "# calculate distance from park to state boundary\n",
    "def calc_park_to_state_distance(park_name,parks_gdf, state_name, states_gdf) -> float:\n",
    "    # Select park geometry\n",
    "    park_row = parks_gdf[parks_gdf['name'] == park_name]\n",
    "    if park_row.empty:\n",
    "        raise ValueError(f\"Park '{park_name}' not found in parks_gdf.\")\n",
    "    park_point = park_row.geometry.iloc[0]\n",
    "\n",
    "    # Select state geometry\n",
    "    state_row = states_gdf[states_gdf['name'] == state_name]\n",
    "    if state_row.empty:\n",
    "        raise ValueError(f\"State '{state_name}' not found in states_gdf.\")\n",
    "    state_poly = state_row.geometry.iloc[0]\n",
    "\n",
    "    # If park is inside state, distance is zero\n",
    "    if state_poly.contains(park_point):\n",
    "        return 0.0\n",
    "\n",
    "    # Find nearest point on state boundary\n",
    "    boundary = state_poly.boundary\n",
    "    nearest_geom = ops.nearest_points(park_point, boundary)[1]\n",
    "\n",
    "    # Compute haversine distance\n",
    "    return calc_park_to_park_distance(\n",
    "        park_point.y, park_point.x,\n",
    "        nearest_geom.y, nearest_geom.x\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d074ae94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2808.1730884567332"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example usage\n",
    "calc_park_to_state_distance(\n",
    "    'Yosemite National Park', parks_df, 'Alabama', states_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1ec509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_topo_queries(df_states, df_tz, template, answer):\n",
    "    results = []\n",
    "    for tz1, tz2 in combinations(df_tz.itertuples(), 2):\n",
    "        for _, st in df_states.iterrows():\n",
    "            # Compute relations against each individual TZ\n",
    "            rels_tz1 = calc_topology(st, tz1, \"state\")\n",
    "            rels_tz2 = calc_topology(st, tz2, \"state\")\n",
    "            # If either relation list includes \"within, covered by\", consider it within the combined area\n",
    "            if \"within\" in rels_tz1 or \"within\" in rels_tz2:\n",
    "                results.append({\n",
    "                    'query':     template.format(tz1=tz1.zone, tz2=tz2.zone, state=st['name']),\n",
    "                    'answer':    answer\n",
    "                })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6c695",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     66\u001b[39m                     json.dump(records, f, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     67\u001b[39m                     f.write(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[43mgenerate_topo_dis_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparks_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# add_topo_queries(states_df, tz_df, \"How is {state} state spatially related to the combined area of {tz1} and {tz2} Time Zones?\", \"within\")               \u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[102]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mgenerate_topo_dis_queries\u001b[39m\u001b[34m(parks_gdf, states_gdf, tz_gdf)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m distance_type \u001b[38;5;129;01min\u001b[39;00m DISTANCE_TYPES:\n\u001b[32m     61\u001b[39m     query = (\n\u001b[32m     62\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWhich state that topologically \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtopo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m combined area of \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[33mtz1\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[33mtz2\u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m Time Zone area is the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdistance_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     63\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpark[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in straight-line distance?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     64\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     records = \u001b[43madd_topo_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     json.dump(records, f, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     67\u001b[39m     f.write(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36madd_topo_queries\u001b[39m\u001b[34m(df_states, df_tz, template, answer)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tz1, tz2 \u001b[38;5;129;01min\u001b[39;00m combinations(df_tz.itertuples(), \u001b[32m2\u001b[39m):\n\u001b[32m     60\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, st \u001b[38;5;129;01min\u001b[39;00m df_states.iterrows():\n\u001b[32m     61\u001b[39m         \u001b[38;5;66;03m# Compute relations against each individual TZ\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         rels_tz1 = \u001b[43mcalc_topology\u001b[49m\u001b[43m(\u001b[49m\u001b[43mst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtz1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m         rels_tz2 = calc_topology(st, tz2, \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m         \u001b[38;5;66;03m# If either relation list includes \"within, covered by\", consider it within the combined area\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcalc_topology\u001b[39m\u001b[34m(state, timezone, direction)\u001b[39m\n\u001b[32m      7\u001b[39m geom_state = state.geometry\n\u001b[32m      8\u001b[39m geom_other = timezone.geometry\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m inter = \u001b[43mgeom_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeom_other\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m ia = inter.area\n\u001b[32m     11\u001b[39m area_state = geom_state.area\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spatial-benchmark/lib/python3.11/site-packages/shapely/geometry/base.py:599\u001b[39m, in \u001b[36mBaseGeometry.intersection\u001b[39m\u001b[34m(self, other, grid_size)\u001b[39m\n\u001b[32m    593\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mintersection\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, grid_size=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    594\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    595\u001b[39m \u001b[33;03m    Returns the intersection of the geometries.\u001b[39;00m\n\u001b[32m    596\u001b[39m \n\u001b[32m    597\u001b[39m \u001b[33;03m    Refer to `shapely.intersection` for full documentation.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshapely\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintersection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrid_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spatial-benchmark/lib/python3.11/site-packages/shapely/decorators.py:77\u001b[39m, in \u001b[36mmultithreading_enabled.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m array_args:\n\u001b[32m     76\u001b[39m         arr.flags.writeable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m arr, old_flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(array_args, old_flags):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/spatial-benchmark/lib/python3.11/site-packages/shapely/set_operations.py:131\u001b[39m, in \u001b[36mintersection\u001b[39m\u001b[34m(a, b, grid_size, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgrid_size parameter only accepts scalar values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.intersection_prec(a, b, grid_size, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "# Which state that topologically contains Eastern Time Zones area is nearest to Voyageurs National Park in straight-line distance?\n",
    "\n",
    "def find_states(tz, topo, states_gdf):\n",
    "    states = []\n",
    "    for _,state in states_gdf.iterrows():\n",
    "        rels = calc_topology(state, tz, \"state\")\n",
    "        if topo in rels:\n",
    "            states.append(state['name'])\n",
    "    return states\n",
    "\n",
    "# some_states = find_states(tz_df[tz_df['zone']=='Central'].iloc[0], 'covered by', states_df)\n",
    "# print(some_states)\n",
    "\n",
    "def find_state_by_distance(park_name, parks_gdf, states_list, states_gdf, distance_type):\n",
    "    distances = []\n",
    "    for state_name in states_list:\n",
    "        dist = calc_park_to_state_distance(park_name, parks_gdf, state_name, states_gdf)\n",
    "        distances.append((state_name, dist))\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    if not distances:\n",
    "        return \"None\"\n",
    "    if distance_type == \"nearest\":\n",
    "        return distances[0][0]\n",
    "    else:\n",
    "        return distances[-1][0]\n",
    "    \n",
    "# find_state_by_distance(\"Yellowstone National Park\", parks_df, some_states, states_df, \"nearest\")\n",
    "\n",
    "def generate_topo_dis_queries(parks_gdf, states_gdf, tz_gdf):\n",
    "    DISTANCE_TYPES = ['nearest', 'farthest']\n",
    "    TOPOLOGIES = ['covered by', 'covers', 'within', 'contains', 'equals', 'overlaps', 'touch', 'disjoint'] \n",
    "    out_fp = Path('../GeoReason_T2_queries/topology_and_distance_queries.jsonl')\n",
    "    out_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_fp.open('w', encoding='utf-8') as f:\n",
    "        for _, park in parks_gdf.iterrows():\n",
    "            for _, tz in tz_gdf.iterrows():\n",
    "                for distance_type in DISTANCE_TYPES:\n",
    "                    for topo in TOPOLOGIES:\n",
    "                        cand_states = find_states(tz, topo, states_gdf)\n",
    "                        if not cand_states:\n",
    "                            answer = \"None\"\n",
    "                        record = []\n",
    "                        answer = find_state_by_distance(park['name'], parks_gdf, cand_states, states_gdf, distance_type)\n",
    "                        query = (\n",
    "                            f\"Which state that topologically {topo} {tz['zone']} Time Zone area is the {distance_type} to \"\n",
    "                            f\"{park['name']} in straight-line distance?\"\n",
    "                        )\n",
    "                        record.append({'query': query, 'answer': answer})\n",
    "                        query = (\n",
    "                            f\"Which time zone that topologically {answer} is the {distance_type} to \"\n",
    "                            f\"{park['name']} in straight-line distance?\"\n",
    "                        )\n",
    "                        json.dump(record, f, ensure_ascii=False)\n",
    "                        f.write('\\n')\n",
    "\n",
    "\n",
    "\n",
    "        for _, park in parks_gdf.iterrows():\n",
    "            for distance_type in DISTANCE_TYPES:\n",
    "                query = (\n",
    "                            f\"Which state that topologically {topo} combined area of {{tz1}} and {{tz2}} Time Zone area is the {distance_type} to \"\n",
    "                            f\"{park['name']} in straight-line distance?\"\n",
    "                        )\n",
    "                records = add_topo_queries(states_df, tz_df, query, topo)\n",
    "                json.dump(records, f, ensure_ascii=False)\n",
    "                f.write('\\n')\n",
    "\n",
    "\n",
    "generate_topo_dis_queries(parks_df, states_df, tz_df)\n",
    "\n",
    "\n",
    "# add_topo_queries(states_df, tz_df, \"How is {state} state spatially related to the combined area of {tz1} and {tz2} Time Zones?\", \"within\")               \n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06f0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "                        f\"How is {st['name']} state spatially related to the combined area of \"\n",
    "                        f\"{tz1.zone} and {tz2.zone} Time Zones?\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5efe5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial-benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
